{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"id":"uPojRlNQPJub"}},{"cell_type":"markdown","source":"Import the required libraries.","metadata":{"id":"oOtnY2y8Om-1"}},{"cell_type":"code","source":"import re\nfrom typing import Dict, List, Optional, Text, Tuple\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n\nimport tensorflow as tf","metadata":{"id":"1Mf4kbp8yOxd","execution":{"iopub.status.busy":"2023-11-15T00:10:34.272149Z","iopub.execute_input":"2023-11-15T00:10:34.272479Z","iopub.status.idle":"2023-11-15T00:10:34.278322Z","shell.execute_reply.started":"2023-11-15T00:10:34.272444Z","shell.execute_reply":"2023-11-15T00:10:34.276852Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Load the dataset","metadata":{"id":"aVb2hhOcgVwU"}},{"cell_type":"markdown","source":"Enter the Unix glob file pattern of the data files.\n\nHere we load the training data. All the data are stored in TensorFlow Record files.\nReplace 'train' with 'eval' or 'test' to load the evaluation or testing data, respectively.","metadata":{"id":"awWJ00JeOyuO"}},{"cell_type":"code","source":"file_pattern = '/kaggle/input/next-day-wildfire-spread/next_day_wildfire_spread_train*'\n#file_pattern_test = '/kaggle/input/next-day-wildfire-spread/next_day_wildfire_spread_test*'","metadata":{"id":"fhHMUbBoOg0k","execution":{"iopub.status.busy":"2023-11-15T00:10:34.280631Z","iopub.execute_input":"2023-11-15T00:10:34.281021Z","iopub.status.idle":"2023-11-15T00:10:34.291446Z","shell.execute_reply.started":"2023-11-15T00:10:34.280971Z","shell.execute_reply":"2023-11-15T00:10:34.289999Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Run the following three cells to define the required library functions for loading the data.\n\nThe first cell defines the name of the variables in the input files and the corrresponding data statistics. The statistics can be used for preprocessing the data. ","metadata":{"id":"OabUJMGqO9NE"}},{"cell_type":"code","source":"\"\"\"Constants for the data reader.\"\"\"\n\nINPUT_FEATURES = ['elevation', 'th', 'vs',  'tmmn', 'tmmx', 'sph', \n                  'pr', 'pdsi', 'NDVI', 'population', 'erc', 'PrevFireMask']\n\nOUTPUT_FEATURES = ['FireMask', ]\n\n# Data statistics \n# For each variable, the statistics are ordered in the form:\n# (min_clip, max_clip, mean, standard deviation)\nDATA_STATS = {\n    # Elevation in m.\n    # 0.1 percentile, 99.9 percentile\n    'elevation': (0.0, 3141.0, 657.3003, 649.0147),\n    \n    # Drought Index (Palmer Drought Severity Index)\n    # 0.1 percentile, 99.9 percentile\n    'pdsi': (-6.12974870967865, 7.876040384292651, -0.0052714925, 2.6823447),\n    \n    #Vegetation index (times 10,000 maybe, since it's supposed to be b/w -1 and 1?)\n    'NDVI': (-9821.0, 9996.0, 5157.625, 2466.6677),  # min, max\n   \n    # Precipitation in mm.\n    # Negative values do not make sense, so min is set to 0.\n    # 0., 99.9 percentile\n    'pr': (0.0, 44.53038024902344, 1.7398051, 4.482833),\n   \n    # Specific humidity.\n    # Negative values do not make sense, so min is set to 0.\n    # The range of specific humidity is up to 100% so max is 1.\n    'sph': (0., 1., 0.0071658953, 0.0042835088),\n    \n    # Wind direction in degrees clockwise from north.\n    # Thus min set to 0 and max set to 360.\n    'th': (0., 360.0, 190.32976, 72.59854),\n    \n    # Min/max temperature in Kelvin.\n    \n    #Min temp\n    # -20 degree C, 99.9 percentile\n    'tmmn': (253.15, 298.94891357421875, 281.08768, 8.982386),\n    \n    #Max temp\n    # -20 degree C, 99.9 percentile\n    'tmmx': (253.15, 315.09228515625, 295.17383, 9.815496),\n    \n    # Wind speed in m/s.\n    # Negative values do not make sense, given there is a wind direction.\n    # 0., 99.9 percentile\n    'vs': (0.0, 10.024310074806237, 3.8500874, 1.4109988),\n    \n    # NFDRS fire danger index energy release component expressed in BTU's per\n    # square foot.\n    # Negative values do not make sense. Thus min set to zero.\n    # 0., 99.9 percentile\n    'erc': (0.0, 106.24891662597656, 37.326267, 20.846027),\n    \n    # Population density\n    # min, 99.9 percentile\n    'population': (0., 2534.06298828125, 25.531384, 154.72331),\n    \n    # We don't want to normalize the FireMasks.\n    # 1 indicates fire, 0 no fire, -1 unlabeled data\n    'PrevFireMask': (-1., 1., 0., 1.),\n    'FireMask': (-1., 1., 0., 1.)\n}","metadata":{"id":"GTTV3tjjCcdn","execution":{"iopub.status.busy":"2023-11-15T00:10:34.293243Z","iopub.execute_input":"2023-11-15T00:10:34.293605Z","iopub.status.idle":"2023-11-15T00:10:34.309773Z","shell.execute_reply.started":"2023-11-15T00:10:34.293556Z","shell.execute_reply":"2023-11-15T00:10:34.308774Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"The following cell defines cropping functions for extracting regions of the desired size from the input data.","metadata":{}},{"cell_type":"code","source":"\"\"\"Library of common functions used in deep learning neural networks.\n\"\"\"\n#YOU PROBABLY WILL NOT USE THESE.\n\ndef random_crop_input_and_output_images(\n    input_img: tf.Tensor,\n    output_img: tf.Tensor,\n    sample_size: int,\n    num_in_channels: int,\n    num_out_channels: int,\n) -> Tuple[tf.Tensor, tf.Tensor]:\n  \"\"\"Randomly axis-align crop input and output image tensors.\n\n  Args:\n    input_img: tensor with dimensions HWC.\n    output_img: tensor with dimensions HWC.\n    sample_size: side length (square) to crop to.\n    num_in_channels: number of channels in input_img.\n    num_out_channels: number of channels in output_img.\n  Returns:\n    input_img: tensor with dimensions HWC.\n    output_img: tensor with dimensions HWC.\n  \"\"\"\n  combined = tf.concat([input_img, output_img], axis=2)\n  combined = tf.image.random_crop(\n      combined,\n      [sample_size, sample_size, num_in_channels + num_out_channels])\n  input_img = combined[:, :, 0:num_in_channels]\n  output_img = combined[:, :, -num_out_channels:]\n  return input_img, output_img\n\n\ndef center_crop_input_and_output_images(\n    input_img: tf.Tensor,\n    output_img: tf.Tensor,\n    sample_size: int,\n) -> Tuple[tf.Tensor, tf.Tensor]:\n  \"\"\"Center crops input and output image tensors.\n\n  Args:\n    input_img: tensor with dimensions HWC.\n    output_img: tensor with dimensions HWC.\n    sample_size: side length (square) to crop to.\n  Returns:\n    input_img: tensor with dimensions HWC.\n    output_img: tensor with dimensions HWC.\n  \"\"\"\n  central_fraction = sample_size / input_img.shape[0]\n  input_img = tf.image.central_crop(input_img, central_fraction)\n  output_img = tf.image.central_crop(output_img, central_fraction)\n  return input_img, output_img","metadata":{"id":"QqGYv21hD-2q","execution":{"iopub.status.busy":"2023-11-15T00:10:34.311919Z","iopub.execute_input":"2023-11-15T00:10:34.312301Z","iopub.status.idle":"2023-11-15T00:10:34.325952Z","shell.execute_reply.started":"2023-11-15T00:10:34.312262Z","shell.execute_reply":"2023-11-15T00:10:34.324951Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"The following cell provides code for parsing the contents of the TensorFlow Record files. In addition to loading the data, it also offers functions for various preprocessing operations, such as clipping, rescaling, or normalizing the data.  ","metadata":{}},{"cell_type":"code","source":"\"\"\"Dataset reader for Earth Engine data.\"\"\"\n\ndef _get_base_key(key: Text) -> Text:\n  \"\"\"Extracts the base key from the provided key.\n\n  Earth Engine exports TFRecords containing each data variable with its\n  corresponding variable name. In the case of time sequences, the name of the\n  data variable is of the form 'variable_1', 'variable_2', ..., 'variable_n',\n  where 'variable' is the name of the variable, and n the number of elements\n  in the time sequence. Extracting the base key ensures that each step of the\n  time sequence goes through the same normalization steps.\n  The base key obeys the following naming pattern: '([a-zA-Z]+)'\n  For instance, for an input key 'variable_1', this function returns 'variable'.\n  For an input key 'variable', this function simply returns 'variable'.\n\n  Args:\n    key: Input key.\n\n  Returns:\n    The corresponding base key.\n\n  Raises:\n    ValueError when `key` does not match the expected pattern.\n  \"\"\"\n  match = re.match(r'([a-zA-Z]+)', key)\n  if match:\n    return match.group(1)\n  raise ValueError(\n      'The provided key does not match the expected pattern: {}'.format(key))\n\n\ndef _clip_and_rescale(inputs: tf.Tensor, key: Text) -> tf.Tensor:\n  \"\"\"Clips and rescales inputs with the stats corresponding to `key`.\n\n  Args:\n    inputs: Inputs to clip and rescale.\n    key: Key describing the inputs.\n\n  Returns:\n    Clipped and rescaled input.\n\n  Raises:\n    ValueError if there are no data statistics available for `key`.\n  \"\"\"\n  base_key = _get_base_key(key)\n  if base_key not in DATA_STATS:\n    raise ValueError(\n        'No data statistics available for the requested key: {}.'.format(key))\n  min_val, max_val, _, _ = DATA_STATS[base_key]\n  inputs = tf.clip_by_value(inputs, min_val, max_val)\n  return tf.math.divide_no_nan((inputs - min_val), (max_val - min_val))\n\n\ndef _clip_and_normalize(inputs: tf.Tensor, key: Text) -> tf.Tensor:\n  \"\"\"Clips and normalizes inputs with the stats corresponding to `key`.\n\n  Args:\n    inputs: Inputs to clip and normalize.\n    key: Key describing the inputs.\n\n  Returns:\n    Clipped and normalized input.\n\n  Raises:\n    ValueError if there are no data statistics available for `key`.\n  \"\"\"\n  base_key = _get_base_key(key)\n  if base_key not in DATA_STATS:\n    raise ValueError(\n        'No data statistics available for the requested key: {}.'.format(key))\n  min_val, max_val, mean, std = DATA_STATS[base_key]\n  inputs = tf.clip_by_value(inputs, min_val, max_val)\n  inputs = inputs - mean\n  return tf.math.divide_no_nan(inputs, std)\n\ndef _get_features_dict(\n    sample_size: int,\n    features: List[Text],\n) -> Dict[Text, tf.io.FixedLenFeature]:\n  \"\"\"Creates a features dictionary for TensorFlow IO.\n\n  Args:\n    sample_size: Size of the input tiles (square).\n    features: List of feature names.\n\n  Returns:\n    A features dictionary for TensorFlow IO.\n  \"\"\"\n  sample_shape = [sample_size, sample_size]\n  features = set(features)\n  columns = [\n      tf.io.FixedLenFeature(shape=sample_shape, dtype=tf.float32)\n      for _ in features\n  ]\n  return dict(zip(features, columns))\n\n\ndef _parse_fn(\n    example_proto: tf.train.Example, data_size: int, sample_size: int,\n    num_in_channels: int, clip_and_normalize: bool,\n    clip_and_rescale: bool, random_crop: bool, center_crop: bool,\n) -> Tuple[tf.Tensor, tf.Tensor]:\n  \"\"\"Reads a serialized example.\n\n  Args:\n    example_proto: A TensorFlow example protobuf.\n    data_size: Size of tiles (square) as read from input files.\n    sample_size: Size the tiles (square) when input into the model.\n    num_in_channels: Number of input channels.\n    clip_and_normalize: True if the data should be clipped and normalized.\n    clip_and_rescale: True if the data should be clipped and rescaled.\n    random_crop: True if the data should be randomly cropped.\n    center_crop: True if the data should be cropped in the center.\n\n  Returns:\n    (input_img, output_img) tuple of inputs and outputs to the ML model.\n  \"\"\"\n  if (random_crop and center_crop):\n    raise ValueError('Cannot have both random_crop and center_crop be True')\n  input_features, output_features = INPUT_FEATURES, OUTPUT_FEATURES\n  feature_names = input_features + output_features\n  features_dict = _get_features_dict(data_size, feature_names)\n  features = tf.io.parse_single_example(example_proto, features_dict)\n\n  if clip_and_normalize:\n    inputs_list = [\n        _clip_and_normalize(features.get(key), key) for key in input_features\n    ]\n  elif clip_and_rescale:\n    inputs_list = [\n        _clip_and_rescale(features.get(key), key) for key in input_features\n    ]\n  else:\n    inputs_list = [features.get(key) for key in input_features]\n  \n  inputs_stacked = tf.stack(inputs_list, axis=0)\n  input_img = tf.transpose(inputs_stacked, [1, 2, 0])\n\n  outputs_list = [features.get(key) for key in output_features]\n  assert outputs_list, 'outputs_list should not be empty'\n  outputs_stacked = tf.stack(outputs_list, axis=0)\n\n  outputs_stacked_shape = outputs_stacked.get_shape().as_list()\n  assert len(outputs_stacked.shape) == 3, ('outputs_stacked should be rank 3'\n                                            'but dimensions of outputs_stacked'\n                                            f' are {outputs_stacked_shape}')\n  output_img = tf.transpose(outputs_stacked, [1, 2, 0])\n\n  if random_crop:\n    input_img, output_img = random_crop_input_and_output_images(\n        input_img, output_img, sample_size, num_in_channels, 1)\n  if center_crop:\n    input_img, output_img = center_crop_input_and_output_images(\n        input_img, output_img, sample_size)\n  return input_img, output_img\n\n\ndef get_dataset(file_pattern: Text, data_size: int, sample_size: int,\n                batch_size: int, num_in_channels: int, compression_type: Text,\n                clip_and_normalize: bool, clip_and_rescale: bool,\n                random_crop: bool, center_crop: bool) -> tf.data.Dataset:\n  \"\"\"Gets the dataset from the file pattern.\n\n  Args:\n    file_pattern: Input file pattern.\n    data_size: Size of tiles (square) as read from input files.\n    sample_size: Size the tiles (square) when input into the model.\n    batch_size: Batch size.\n    num_in_channels: Number of input channels.\n    compression_type: Type of compression used for the input files.\n    clip_and_normalize: True if the data should be clipped and normalized, False\n      otherwise.\n    clip_and_rescale: True if the data should be clipped and rescaled, False\n      otherwise.\n    random_crop: True if the data should be randomly cropped.\n    center_crop: True if the data shoulde be cropped in the center.\n\n  Returns:\n    A TensorFlow dataset loaded from the input file pattern, with features\n    described in the constants, and with the shapes determined from the input\n    parameters to this function.\n  \"\"\"\n  if (clip_and_normalize and clip_and_rescale):\n    raise ValueError('Cannot have both normalize and rescale.')\n  dataset = tf.data.Dataset.list_files(file_pattern)\n  dataset = dataset.interleave(\n      lambda x: tf.data.TFRecordDataset(x, compression_type=compression_type),\n      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n  dataset = dataset.map(\n      lambda x: _parse_fn(  # pylint: disable=g-long-lambda\n          x, data_size, sample_size, num_in_channels, clip_and_normalize,\n          clip_and_rescale, random_crop, center_crop),\n      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n  dataset = dataset.batch(batch_size)\n  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n  return dataset","metadata":{"id":"VBvI9FuGEC09","execution":{"iopub.status.busy":"2023-11-15T00:10:34.329769Z","iopub.execute_input":"2023-11-15T00:10:34.330231Z","iopub.status.idle":"2023-11-15T00:10:34.368283Z","shell.execute_reply.started":"2023-11-15T00:10:34.330176Z","shell.execute_reply":"2023-11-15T00:10:34.367133Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Load the dataset.\n\nThe data are stored as 64x64 km regions. For each data sample, we extract a random 32x32 km region. In the following function call, we do not clip, rescale or normalize the data. ","metadata":{"id":"rdNDytnsPTVK"}},{"cell_type":"code","source":"side_length = 32 #length of the side of the square you select (so, e.g. pick 64 if you don't want any random cropping)\nnum_obs = 100 #batch size\n\ndataset = get_dataset(\n      file_pattern,\n      data_size=64,\n      sample_size=side_length,\n      batch_size=num_obs,\n      num_in_channels=12,\n      compression_type=None,\n      clip_and_normalize=False,\n      clip_and_rescale=False,\n      random_crop=True,\n      center_crop=False)","metadata":{"id":"X1jBBEinQbM0","execution":{"iopub.status.busy":"2023-11-15T00:10:34.370132Z","iopub.execute_input":"2023-11-15T00:10:34.370887Z","iopub.status.idle":"2023-11-15T00:10:35.262644Z","shell.execute_reply.started":"2023-11-15T00:10:34.370830Z","shell.execute_reply":"2023-11-15T00:10:35.261683Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\nUser settings:\n\n   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n   KMP_BLOCKTIME=0\n   KMP_SETTINGS=1\n   KMP_WARNINGS=0\n\nEffective settings:\n\n   KMP_ABORT_DELAY=0\n   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n   KMP_ALIGN_ALLOC=64\n   KMP_ALL_THREADPRIVATE=128\n   KMP_ATOMIC_MODE=2\n   KMP_BLOCKTIME=0\n   KMP_CPUINFO_FILE: value is not defined\n   KMP_DETERMINISTIC_REDUCTION=false\n   KMP_DEVICE_THREAD_LIMIT=2147483647\n   KMP_DISP_NUM_BUFFERS=7\n   KMP_DUPLICATE_LIB_OK=false\n   KMP_ENABLE_TASK_THROTTLING=true\n   KMP_FORCE_REDUCTION: value is not defined\n   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n   KMP_FORKJOIN_BARRIER='2,2'\n   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_GTID_MODE=3\n   KMP_HANDLE_SIGNALS=false\n   KMP_HOT_TEAMS_MAX_LEVEL=1\n   KMP_HOT_TEAMS_MODE=0\n   KMP_INIT_AT_FORK=true\n   KMP_LIBRARY=throughput\n   KMP_LOCK_KIND=queuing\n   KMP_MALLOC_POOL_INCR=1M\n   KMP_NUM_LOCKS_IN_BLOCK=1\n   KMP_PLAIN_BARRIER='2,2'\n   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_REDUCTION_BARRIER='1,1'\n   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n   KMP_SCHEDULE='static,balanced;guided,iterative'\n   KMP_SETTINGS=true\n   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n   KMP_STACKOFFSET=64\n   KMP_STACKPAD=0\n   KMP_STACKSIZE=8M\n   KMP_STORAGE_MAP=false\n   KMP_TASKING=2\n   KMP_TASKLOOP_MIN_TASKS=0\n   KMP_TASK_STEALING_CONSTRAINT=1\n   KMP_TEAMS_THREAD_LIMIT=4\n   KMP_TOPOLOGY_METHOD=all\n   KMP_USE_YIELD=1\n   KMP_VERSION=false\n   KMP_WARNINGS=false\n   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n   OMP_ALLOCATOR=omp_default_mem_alloc\n   OMP_CANCELLATION=false\n   OMP_DEFAULT_DEVICE=0\n   OMP_DISPLAY_AFFINITY=false\n   OMP_DISPLAY_ENV=false\n   OMP_DYNAMIC=false\n   OMP_MAX_ACTIVE_LEVELS=1\n   OMP_MAX_TASK_PRIORITY=0\n   OMP_NESTED: deprecated; max-active-levels-var=1\n   OMP_NUM_THREADS: value is not defined\n   OMP_PLACES: value is not defined\n   OMP_PROC_BIND='intel'\n   OMP_SCHEDULE='static'\n   OMP_STACKSIZE=8M\n   OMP_TARGET_OFFLOAD=DEFAULT\n   OMP_THREAD_LIMIT=2147483647\n   OMP_WAIT_POLICY=PASSIVE\n   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"TF Datasets are loaded lazily, so materialize the first batch of inputs and labels.","metadata":{"id":"Ca8USco0PdG3"}},{"cell_type":"code","source":"inputs, labels = next(iter(dataset)) \n#inputs_test, labels_test = next(iter(dataset_test)) \n#Are there two assignments happening on every iteration because dataset stores inputs with labels?\n#print(inputs.shape) #(100, 32, 32, 12)\n#print(labels.shape) #(100, 32, 32, 1)\n#print(inputs[0, :, :, 11]) #Trying to grab the previous fire mask. (Apparent) success!\n#print(labels[0,:, :, 0]) #Ok, I think the labels are the fire mask. (That also accords with standard usage of the term.)","metadata":{"id":"Ml7Rg8aCQiTT","execution":{"iopub.status.busy":"2023-11-15T00:10:35.264145Z","iopub.execute_input":"2023-11-15T00:10:35.264421Z","iopub.status.idle":"2023-11-15T00:10:35.602552Z","shell.execute_reply.started":"2023-11-15T00:10:35.264386Z","shell.execute_reply":"2023-11-15T00:10:35.601538Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"I'd like to consider the average neighbor fire scores eventually. The function below helps me do that. Form: array_out = avg_neighbors(array_in)","metadata":{}},{"cell_type":"code","source":"#Eventually would like a function that takes in an input array of dimensions nxn, \n#outputs an array that gives avg of each cell's neighbors:\ndef avg_neighbors(array_in):\n    #Check input\n    if array_in.shape[0] != array_in.shape[1]:\n        raise Exception('Only square arrays make sense here, since you\\'re analyzing square arrays.')\n    #Maybe should also do type-checking, but leave it for now.\n    \n    #Prepare the output array:\n    n = array_in.shape[0] \n    array_out = np.zeros((n,n))\n    \n    #Guess who doesn't know how to do signal processing in Python...\n    \n    for i in range(n):\n        for j in range(n):\n            if i == 0:\n                #Upper edge\n                if j == 0:\n                    #Upper left corner\n                    sum_neighbors = array_in[i+1, j] + array_in[i, j+1] + array_in[i+1, j+1]\n                    avg = sum_neighbors/3\n                    \n                elif j == (n-1):\n                    #Upper right corner\n                    sum_neighbors = array_in[i, j-1] + array_in[i+1, j] + array_in[i+1, j-1]\n                    avg = sum_neighbors/3\n                    \n                else:\n                    #Upper edge except corners\n                    sum_neighbors = array_in[i, j-1] + array_in[i+1, j] + array_in[i, j+1] + array_in[i+1, j-1] + array_in[i+1, j+1]\n                    avg = sum_neighbors/5\n                   \n            elif i == (n-1):\n                #Lower edge\n                if j == 0:\n                    #Lower left corner\n                    sum_neighbors = array_in[i-1, j] + array_in[i, j+1] + array_in[i-1, j+1]\n                    avg = sum_neighbors/3\n                    \n                elif j == (n-1):\n                    #Lower right corner\n                    sum_neighbors = array_in[i, j-1] + array_in[i-1, j] + array_in[i-1, j-1]\n                    avg = sum_neighbors/3\n                    \n                else:\n                    #Lower edge except corners\n                    sum_neighbors = array_in[i, j-1] + array_in[i, j+1] + array_in[i-1, j] + array_in[i-1, j-1] + array_in[i-1, j+1]\n                    avg = sum_neighbors/5\n                    \n            else:\n                if j == 0:\n                    #Left edge except corners\n                    sum_neighbors = array_in[i-1, j] + array_in[i+1, j] + array_in[i, j+1] + array_in[i-1, j+1] + array_in[i+1, j+1]\n                    avg = sum_neighbors/5\n                    \n                elif j == (n-1):\n                    #Right edge except corners\n                    sum_neighbors = array_in[i-1, j] + array_in[i+1, j] + array_in[i, j-1] + array_in[i-1, j-1] + array_in[i+1, j-1]\n                    avg = sum_neighbors/5\n                    \n                else:\n                    #Not on any edge or corner\n                    sum_neighbors = array_in[i, j+1] + array_in[i, j-1] + array_in[i-1, j] + array_in[i+1, j] + \\\n                                    array_in[i-1, j-1] + array_in[i-1, j+1] + array_in[i+1, j-1] + array_in[i+1, j+1]\n                    avg = sum_neighbors/8\n                    \n                    \n            array_out[i,j] = avg\n            #/for loop body\n        \n    return array_out\n                    \n                    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:35.604494Z","iopub.execute_input":"2023-11-15T00:10:35.604830Z","iopub.status.idle":"2023-11-15T00:10:35.629465Z","shell.execute_reply.started":"2023-11-15T00:10:35.604774Z","shell.execute_reply":"2023-11-15T00:10:35.628522Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Here, I test the function: ","metadata":{}},{"cell_type":"code","source":"#Test the function from above:\nimport numpy as np\narr = [[1,2,3], \n       [4,5,6],\n       [7,8,9]]\narr = np.array(arr)\narr_avgs = avg_neighbors(arr)\nprint(arr_avgs)\n#Good: appears to work","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:35.633003Z","iopub.execute_input":"2023-11-15T00:10:35.633998Z","iopub.status.idle":"2023-11-15T00:10:35.648353Z","shell.execute_reply.started":"2023-11-15T00:10:35.633951Z","shell.execute_reply":"2023-11-15T00:10:35.647270Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[[3.66666667 3.8        4.33333333]\n [4.6        5.         5.4       ]\n [5.66666667 6.2        6.33333333]]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Let's experiment to see if I know what's going on in the code cell 35 above:\nls = ['Staring', 'at', 'the', 'tiny', 'planet', 'God', 'calculated', 'again']\nls_iter = iter(ls)\nfor i in range (len(ls)):\n    print(next(ls_iter))\n    \n#Ok, so far so good\nls2 = [['There', 'was'], ['no', 'room'], ['for', 'a'], ['continuous', 'forest']]\nls2_iter = iter(ls2)\nfor i in range (len(ls2)):\n    first_word, second_word = next(ls2_iter)\n    print(first_word, second_word)\n#Yes, ok, working as expected\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:35.649380Z","iopub.execute_input":"2023-11-15T00:10:35.649626Z","iopub.status.idle":"2023-11-15T00:10:35.661919Z","shell.execute_reply.started":"2023-11-15T00:10:35.649586Z","shell.execute_reply":"2023-11-15T00:10:35.660665Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Staring\nat\nthe\ntiny\nplanet\nGod\ncalculated\nagain\nThere was\nno room\nfor a\ncontinuous forest\n","output_type":"stream"}]},{"cell_type":"code","source":"#Let's try using the function above on the previous fire masks:\n#This code (is supposed to) find the first \"interesting\" previous fire mask and compute the avg number of neighboring \n#on-fire cells for each cell\n\nprev_fire_masks = inputs[:, :, :, 11] #observation number, pixel row, pixel col\n#prev_fire_masks_test = inputs_test[:, :, :, 11] #observation number, pixel row, pixel col\n\nfound_it_flag = 0 #will set to 1 once we've found our \"interesting\" fire mask\nimg_num = 0\nwhile found_it_flag == 0:\n    fire_mask = np.array(prev_fire_masks[img_num, :, :])\n    if (np.all( (fire_mask == 0)) ): #if boring picture where there's no fire, toss it\n        img_num = img_num + 1\n    elif (np.all( np.invert(fire_mask == -1) )): #if NO data is missing data, cond. is TRUE --> you want this one\n        test_img = fire_mask\n        found_it_flag = 1\n    else:\n        img_num = img_num + 1\n\nnp.set_printoptions(threshold=np.inf) #this just stops Jupyter from truncating the output\nprint('fire mask:\\n', fire_mask, '\\n\\n')\nprint('computed avg neighbor fire mask:\\n', avg_neighbors(fire_mask))\n#Note: don't freak out when you see the second matrix \"look bigger\" than the first. The dimensions are correct; the second matrix\n#is just visually larger because instead of 0s and 1s its entries are 3fs.\n#Tested with small grids (9x9) and appears to work.","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:35.663095Z","iopub.execute_input":"2023-11-15T00:10:35.663331Z","iopub.status.idle":"2023-11-15T00:10:35.723571Z","shell.execute_reply.started":"2023-11-15T00:10:35.663301Z","shell.execute_reply":"2023-11-15T00:10:35.722573Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"fire mask:\n [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0.]] \n\n\ncomputed avg neighbor fire mask:\n [[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.125 0.25  0.25  0.125 0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.125 0.125 0.125 0.125 0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.125 0.25  0.25  0.125 0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]\n [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n  0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In the next several cells, we eliminate observations where there is missing or uncertain data in the previous fire mask.","metadata":{}},{"cell_type":"code","source":"#Try to eliminate all observations where there are uncertain squares in the previous fire mask.\nprev_masks_array = np.array(inputs[:, :, :, 11])\n#print(prev_masks_array.shape) #100x32x32—good!\n\n#Build the array of certain data AND SAVE THE INDICES\nfirst_find_flag = 1\ncount = 0\nindices = []\n\nfor img_num in range(num_obs): \n    fire_mask = np.array(prev_fire_masks[img_num, :, :])\n    if (np.all( np.invert(fire_mask == -1) )): #If no missing data, condition is TRUE.\n        count += 1\n        indices.append(img_num)\n        if first_find_flag == 1: #If you need to start the array\n            certain_prev_fire_masks = fire_mask\n            first_find_flag = 0  #Remember to turn the flag off!\n        else:\n            certain_prev_fire_masks = np.dstack((certain_prev_fire_masks, fire_mask)) #d\n            \n\n#Test: You want the printouts from the following three lines to be consistent\nprint(certain_prev_fire_masks.shape)\nprint(count) \nprint(len(indices))\n#Good, they are.\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:35.725233Z","iopub.execute_input":"2023-11-15T00:10:35.725713Z","iopub.status.idle":"2023-11-15T00:10:35.765774Z","shell.execute_reply.started":"2023-11-15T00:10:35.725617Z","shell.execute_reply":"2023-11-15T00:10:35.764624Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"(32, 32, 75)\n75\n75\n","output_type":"stream"}]},{"cell_type":"code","source":"#Now that I've found the observations with \"pristine\" previous fire masks, I'd like to get those observations' features matrices\nfull_input_array = np.array(inputs) #100x32x32x12\n\nfor i, index in enumerate(indices):\n    if i == 0:\n        certain_input_array = full_input_array[index,:,:,:]\n        print(certain_input_array.shape) #32x32x12\n    elif i == 1:\n        certain_input_array = np.concatenate((certain_input_array[..., np.newaxis], full_input_array[index,:,:,:, np.newaxis]), axis=3)\n    else:\n        certain_input_array = np.concatenate((certain_input_array, full_input_array[index,:,:,:, np.newaxis]), axis=3)\n        \nprint(certain_input_array.shape)\n#SUCCESS! :) :) :) \n#certain_input_array now holds only the 77 observations with certain previous fire masks\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:35.767145Z","iopub.execute_input":"2023-11-15T00:10:35.767445Z","iopub.status.idle":"2023-11-15T00:10:35.849958Z","shell.execute_reply.started":"2023-11-15T00:10:35.767398Z","shell.execute_reply":"2023-11-15T00:10:35.848902Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(32, 32, 12)\n(32, 32, 12, 75)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Also want the labels at only these indices and the average neighbor value matrices\nfull_labels = np.array(labels)\n#print(labels.shape) 100x32x32x1, as expected\n\nfor i, index in enumerate(indices):\n    if i == 0:\n        #labels\n        certain_labels = full_labels[index,:,:,:] #32x32x1\n        \n        #avg neighbor values\n        surrounding_fire_scores = avg_neighbors(full_labels[index,:,:,:])\n        surrounding_fire_scores = surrounding_fire_scores[..., np.newaxis]\n        \n    else:\n        #labels\n        certain_labels = np.concatenate((certain_labels, full_labels[index,:,:,:]), axis=2)\n        \n        #avg neighbor values\n        avg_mat = avg_neighbors(full_labels[index,:,:,:])\n        surrounding_fire_scores = np.concatenate((surrounding_fire_scores, avg_mat[...,np.newaxis]), axis=2)\n\n#Printouts from following lines should agree...\nprint(certain_labels.shape) #32x32x77 \nprint(surrounding_fire_scores.shape) #32x32x77 \n#... and they do! :)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:35.854055Z","iopub.execute_input":"2023-11-15T00:10:35.854379Z","iopub.status.idle":"2023-11-15T00:10:36.831544Z","shell.execute_reply.started":"2023-11-15T00:10:35.854339Z","shell.execute_reply":"2023-11-15T00:10:36.830503Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(32, 32, 75)\n(32, 32, 75)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Function to identify certain observations in the previous fire mask and return:\n#1) a list of their indices in the batch (need this to grab the right ones from the labels) and \n#2) the actual array of certain observations\n\ndef elim_uncertain(prev_fire_mask_batch):\n    \n    prev_masks_array = np.array(prev_fire_mask_batch)\n    print(prev_masks_array.shape)\n    num_imgs, rows, cols = prev_masks_array.shape\n    #Build the array of certain data AND SAVE THE INDICES\n    first_find_flag = 1\n    count = 0\n    indices = []\n\n    for img_num in range(num_imgs): \n        fire_mask = prev_fire_mask_batch[img_num, :, :] #grab the \"working fire mask\" off the pile\n        \n        if (np.all( np.invert(fire_mask == -1) )): #If no missing data, condition is TRUE.\n            count += 1\n            indices.append(img_num)\n            if first_find_flag == 1: #If you need to start the array\n                certain_prev_fire_masks_batch = fire_mask\n                first_find_flag = 0  #Remember to turn the flag off!\n            else:\n                certain_prev_fire_masks_batch = np.dstack((certain_prev_fire_masks_batch, fire_mask)) \n    \n    return certain_prev_fire_masks_batch, indices","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:36.832934Z","iopub.execute_input":"2023-11-15T00:10:36.833235Z","iopub.status.idle":"2023-11-15T00:10:36.842221Z","shell.execute_reply.started":"2023-11-15T00:10:36.833197Z","shell.execute_reply":"2023-11-15T00:10:36.841394Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Function to extract only the labels (i.e. current fire masks) from the certain observations\ndef extract_certain_labels(certain_indices, og_labels):\n    \n    for i, index in enumerate(certain_indices):\n        if i == 0:\n            extracted_labels = og_labels[index,:,:,:] #the og_labels dimensions are batch_size by sidelength by sidelength by 1\n        else:\n            #labels\n            extracted_labels = np.concatenate((extracted_labels, og_labels[index,:,:,:]), axis=2)\n\n    return extracted_labels","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:36.843647Z","iopub.execute_input":"2023-11-15T00:10:36.843921Z","iopub.status.idle":"2023-11-15T00:10:36.863079Z","shell.execute_reply.started":"2023-11-15T00:10:36.843888Z","shell.execute_reply":"2023-11-15T00:10:36.861702Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Create multi-D array of neighbor fire values\ndef avg_neighbor_batch(batch_in):\n    rows, cols, batch_size = batch_in.shape #ordering of dimensions here meant to be compatible with elim_uncertain and extract_certain_labels\n    batch_out = np.zeros((rows, cols, batch_size))\n    for i in range(batch_size):\n        working_arr = batch_in[:,:,i]\n        avgd_arr = avg_neighbors(working_arr)\n        batch_out[:,:,i] =  avgd_arr\n    #/for loop\n    \n    return batch_out","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:36.864626Z","iopub.execute_input":"2023-11-15T00:10:36.864949Z","iopub.status.idle":"2023-11-15T00:10:36.877244Z","shell.execute_reply.started":"2023-11-15T00:10:36.864912Z","shell.execute_reply":"2023-11-15T00:10:36.876076Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#Create multi-D array of distance neighbor fire values\ndef distance_batch(batch_in):\n    rows, cols, batch_size = batch_in.shape #ordering of dimensions here meant to be compatible with elim_uncertain and extract_certain_labels\n    batch_out = np.zeros((rows, cols, batch_size))\n    for i in range(batch_size):\n        working_arr = batch_in[:,:,i]\n        calculated_arr = calc_distance(working_arr)\n        batch_out[:,:,i] =  calculated_arr\n    #/for loop\n    \n    return batch_out","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:36.878496Z","iopub.execute_input":"2023-11-15T00:10:36.879389Z","iopub.status.idle":"2023-11-15T00:10:36.893765Z","shell.execute_reply.started":"2023-11-15T00:10:36.879346Z","shell.execute_reply":"2023-11-15T00:10:36.892529Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#eliminate the indices who were unceartin in the other features too\ndef elim_indices(indices_to_keep, feature_mask):\n    #mask_array = np.array(feature_mask)\n    feature_mask_elim = []\n\n    for ind in indices_to_keep: \n        feature_mask_elim.append(feature_mask[ind, :, :])\n    \n    feature_mask_elim = np.array(feature_mask_elim)\n    #print(len(feature_mask_elim))\n    return feature_mask_elim","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:36.895555Z","iopub.execute_input":"2023-11-15T00:10:36.896053Z","iopub.status.idle":"2023-11-15T00:10:36.907841Z","shell.execute_reply.started":"2023-11-15T00:10:36.896007Z","shell.execute_reply":"2023-11-15T00:10:36.906587Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import math\ndef calc_distance(matrix):\n    rows, cols = len(matrix), len(matrix[0])\n    max_distance = math.sqrt(rows**2 + cols**2) \n    output = [[max_distance for _ in range(cols)] for _ in range(rows)]\n        \n    for i in range(rows):\n        for j in range(cols):\n            if matrix[i][j] == 1:\n                output[i][j] = 0\n            else:\n                for x in range(rows):\n                    for y in range(cols):\n                        if matrix[x][y] == 1:\n                            euclidean_distance = math.sqrt((i - x)**2 + (j - y)**2)\n                            distance = 1 - 1/euclidean_distance if euclidean_distance != 0 else 0\n                            output[i][j] = min(output[i][j], distance)\n    \n    # Format the output to remove the decimal from zeros\n    formatted_output = [[int(value) if value == 0 else value for value in row] for row in output]\n    return formatted_output\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:36.909341Z","iopub.execute_input":"2023-11-15T00:10:36.909846Z","iopub.status.idle":"2023-11-15T00:10:36.921769Z","shell.execute_reply.started":"2023-11-15T00:10:36.909798Z","shell.execute_reply":"2023-11-15T00:10:36.920875Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#test calc_distance function\narray_10x10 = [\n    [0, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n    [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n    [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n    [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n    [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n    [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n    [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n]\n\ndistance_matrix = calc_distance(array_10x10)\noriginal = np.array(array_10x10)\nprint(original, \"\\n\")\nprint(np.array(distance_matrix))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:10:36.923497Z","iopub.execute_input":"2023-11-15T00:10:36.923874Z","iopub.status.idle":"2023-11-15T00:10:36.948617Z","shell.execute_reply.started":"2023-11-15T00:10:36.923832Z","shell.execute_reply":"2023-11-15T00:10:36.947469Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[[0 0 0 1 1 0 0 0 1 0]\n [1 0 0 0 0 0 1 0 0 0]\n [0 1 0 0 0 0 0 1 0 0]\n [0 0 0 0 1 0 1 0 0 0]\n [0 0 0 0 1 0 0 0 0 0]\n [0 0 0 1 0 0 0 0 1 0]\n [0 1 0 0 0 0 0 0 0 1]\n [0 0 0 0 0 0 1 1 0 0]\n [0 0 0 1 0 0 0 0 0 0]\n [0 0 0 0 1 0 0 0 0 0]] \n\n[[0.         0.29289322 0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.29289322 0.         0.         0.\n  0.         0.         0.         0.29289322]\n [0.         0.         0.         0.29289322 0.         0.29289322\n  0.         0.         0.         0.5       ]\n [0.29289322 0.         0.29289322 0.         0.         0.\n  0.         0.         0.29289322 0.5527864 ]\n [0.5527864  0.5        0.29289322 0.         0.         0.\n  0.         0.29289322 0.         0.29289322]\n [0.29289322 0.         0.         0.         0.         0.29289322\n  0.5        0.         0.         0.        ]\n [0.         0.         0.         0.         0.29289322 0.29289322\n  0.         0.         0.         0.        ]\n [0.29289322 0.         0.29289322 0.         0.29289322 0.\n  0.         0.         0.         0.        ]\n [0.5527864  0.5        0.         0.         0.         0.29289322\n  0.         0.         0.29289322 0.5       ]\n [0.68377223 0.5527864  0.29289322 0.         0.         0.\n  0.5        0.5        0.5527864  0.64644661]]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Test functions above:\nimport numpy as np\nfull_prev_fire_masks = np.array(inputs[:,:,:,11]) #just grabs the previous fire masks from the full observation multi-D array\nfull_curr_fire_masks = np.array(labels) #100x32x32x1\n\ncertain_prev_masks, certain_indices = elim_uncertain(full_prev_fire_masks) #32x32x86 (generally: sidelength^2 x #certain obs.)\ncertain_labels = extract_certain_labels(certain_indices, full_curr_fire_masks) #32x32x86 (generally: sidelength^2 x #certain obs.)\navg_neighbors_feat = avg_neighbor_batch(certain_prev_masks) #32x32x86 (generally: sidelength^2 x #certain obs.)\neuclid_distance = distance_batch(certain_prev_masks)\nprint(len(avg_neighbors_feat))\nprint(len(euclid_distance))\n\n#Imple neu\ncleaned_elevation = elim_indices(certain_indices, np.array(inputs[:,:,:,0]))\ncleaned_wind_dir = elim_indices(certain_indices, np.array(inputs[:,:,:,1]))\ncleaned_wind_velo = elim_indices(certain_indices, np.array(inputs[:,:,:,2]))\ncleaned_temp_min = elim_indices(certain_indices, np.array(inputs[:,:,:,3]))\ncleaned_temp_max = elim_indices(certain_indices, np.array(inputs[:,:,:,4]))\ncleaned_humidity = elim_indices(certain_indices, np.array(inputs[:,:,:,5]))\ncleaned_precipitation = elim_indices(certain_indices, np.array(inputs[:,:,:,6]))\ncleaned_drought = elim_indices(certain_indices, np.array(inputs[:,:,:,7]))\ncleaned_vegetation = elim_indices(certain_indices, np.array(inputs[:,:,:,8]))\ncleaned_population = elim_indices(certain_indices, np.array(inputs[:,:,:,9]))\ncleaned_ERC = elim_indices(certain_indices, np.array(inputs[:,:,:,10]))\n#print(cleaned_elevation)\n#Success! Note that new format for certain_labels and certain_prev_masks is rows, cols, index in (new, certain-only) pile.","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:13:02.759865Z","iopub.execute_input":"2023-11-15T00:13:02.760859Z","iopub.status.idle":"2023-11-15T00:18:16.105997Z","shell.execute_reply.started":"2023-11-15T00:13:02.760804Z","shell.execute_reply":"2023-11-15T00:18:16.105004Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"(100, 32, 32)\n32\n32\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"#Benchmark method: Try linear regression based on only:\n#1) whether a given pixel is currently on fire and \n#2) number of neighbors that are currently on fire\n\n#Vectorize previous fire masks\nflat_prev_masks = []\n\n#Remembering that Python is zero-indexed is going to be VERY IMPORTANT in the below!\nfor obs in range(certain_prev_masks.shape[2]):\n    for row in range(certain_prev_masks.shape[0]):\n        for col in range(certain_prev_masks.shape[1]):\n            flat_prev_masks.append(certain_prev_masks[row, col, obs])\nflat_prev_masks = np.array(flat_prev_masks)\n\n#Vectorize euc distance\nflat_euclid_distance = []\nfor obs in range(euclid_distance.shape[2]):\n    for row in range(euclid_distance.shape[0]):\n        for col in range(euclid_distance.shape[1]):\n            flat_euclid_distance.append(euclid_distance[row, col, obs])\nflat_euclid_distance = np.array(flat_euclid_distance)\n\nflat_elevation = []\nfor obs in range(cleaned_elevation.shape[2]):\n    for row in range(cleaned_elevation.shape[0]):\n        for col in range(cleaned_elevation.shape[1]):\n            flat_elevation.append(cleaned_elevation[row, col, obs])\nflat_elevation = np.array(flat_elevation)\n\nflat_wind_dir = []\nfor obs in range(cleaned_wind_dir.shape[2]):\n    for row in range(cleaned_wind_dir.shape[0]):\n        for col in range(cleaned_wind_dir.shape[1]):\n            flat_wind_dir.append(cleaned_wind_dir[row, col, obs])\nflat_wind_dir = np.array(flat_wind_dir)\n\nflat_wind_velo = []\nfor obs in range(cleaned_wind_velo.shape[2]):\n    for row in range(cleaned_wind_velo.shape[0]):\n        for col in range(cleaned_wind_velo.shape[1]):\n            flat_wind_velo.append(cleaned_wind_velo[row, col, obs])\nflat_wind_velo = np.array(flat_wind_velo)\n\nflat_temp_min = []\nfor obs in range(cleaned_temp_min.shape[2]):\n    for row in range(cleaned_temp_min.shape[0]):\n        for col in range(cleaned_temp_min.shape[1]):\n            flat_temp_min.append(cleaned_temp_min[row, col, obs])\nflat_temp_min = np.array(flat_temp_min)\n\nflat_temp_max = []\nfor obs in range(cleaned_temp_max.shape[2]):\n    for row in range(cleaned_temp_max.shape[0]):\n        for col in range(cleaned_temp_max.shape[1]):\n            flat_temp_max.append(cleaned_temp_max[row, col, obs])\nflat_temp_max = np.array(flat_temp_max)\n\nflat_humidity = []\nfor obs in range(cleaned_humidity.shape[2]):\n    for row in range(cleaned_humidity.shape[0]):\n        for col in range(cleaned_humidity.shape[1]):\n            flat_humidity.append(cleaned_humidity[row, col, obs])\nflat_humidity = np.array(flat_humidity)\n\nflat_precipitation = []\nfor obs in range(cleaned_precipitation.shape[2]):\n    for row in range(cleaned_precipitation.shape[0]):\n        for col in range(cleaned_precipitation.shape[1]):\n            flat_precipitation.append(cleaned_precipitation[row, col, obs])\nflat_precipitation = np.array(flat_precipitation)\n\nflat_drought = []\nfor obs in range(cleaned_drought.shape[2]):\n    for row in range(cleaned_drought.shape[0]):\n        for col in range(cleaned_drought.shape[1]):\n            flat_drought.append(cleaned_drought[row, col, obs])\nflat_drought = np.array(flat_drought)\n\nflat_vegetation = []\nfor obs in range(cleaned_vegetation.shape[2]):\n    for row in range(cleaned_vegetation.shape[0]):\n        for col in range(cleaned_vegetation.shape[1]):\n            flat_vegetation.append(cleaned_vegetation[row, col, obs])\nflat_vegetation = np.array(flat_vegetation)\n\nflat_population = []\nfor obs in range(cleaned_population.shape[2]):\n    for row in range(cleaned_population.shape[0]):\n        for col in range(cleaned_population.shape[1]):\n            flat_population.append(cleaned_population[row, col, obs])\nflat_population = np.array(flat_population)\n\nflat_ERC = []\nfor obs in range(cleaned_ERC.shape[2]):\n    for row in range(cleaned_ERC.shape[0]):\n        for col in range(cleaned_ERC.shape[1]):\n            flat_ERC.append(cleaned_ERC[row, col, obs])\nflat_ERC = np.array(flat_ERC)\n\n#print(flat_prev_masks.shape)\n#print(flat_avg_nbrs.shape)\nX_TRAIN_FEATURES = ['prev_fire', \n                    'euclid_distance', \n                    'elevation', 'wind_dir', 'wind_velo', 'temp_min', 'temp_max', 'humidity', 'precipitation', 'drought', 'vegetation', 'population', 'ERC']\nX_train = np.vstack((\n    np.transpose(flat_prev_masks), \n    np.transpose(flat_euclid_distance),\n    np.transpose(flat_elevation),\n    np.transpose(flat_wind_dir),\n    np.transpose(flat_wind_velo),\n    np.transpose(flat_temp_min),\n    np.transpose(flat_temp_max),\n    np.transpose(flat_humidity),\n    np.transpose(flat_precipitation),\n    np.transpose(flat_drought),\n    np.transpose(flat_vegetation),\n    np.transpose(flat_population),\n    np.transpose(flat_ERC)\n))\n\nX_train = np.transpose(X_train) #so that observations correspond to rows now\n\n#Vectorize labels\nflat_labels = []\nfor obs in range(certain_labels.shape[2]):\n    for row in range(certain_labels.shape[0]):\n        for col in range(certain_labels.shape[1]):\n            flat_labels.append(certain_labels[row, col, obs])\nflat_labels = np.array(flat_labels)\n\nY_train = flat_labels\n#print(Y_train.shape)\n\nvariables = [\"currently on fire?\", \"# of neighbors currently on fire\"]\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nX_train_r, X_test_r, Y_train_r, Y_test_r = train_test_split(X_train, Y_train, test_size=0.20, random_state=42)\n\nmodel = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, min_samples_leaf = 3)\n#model.fit(X_train, Y_train)\n\n\n#print('training R2-score:', np.round(   r2_score(  Y_train, lr_fire.predict(X_train)),2  )   ) \n\nk = 10  # for example, you can change this value as needed\nscores = cross_val_score(model, X_train, Y_train, cv=k)\n#print(\"Cross Val: \", scores.mean())\n#model = RandomForestClassifier(criterion = \"gini\", n_estimators = 15)\nmodel.fit(X_train_r, Y_train_r)\n\ntree = export_graphviz(model, None,\n                      feature_names = [\"prev Fire\", \"euc_distance\", \" elevation\", \"wind_dir\",\n                                      \"wind_velo\", \"temp_min\", \"temp_max\", \"humidity\", \n                                      \"precipitation\", \"drought\", \"vegatation\", \"population\", \"ERC\"],\n                      rounded = True, filled = True)\n#print(\"normal score: \",model.score(X_test_r, Y_test_r))\n#graphviz.Source(tree)\n\n\n\n\nimportances = model.feature_importances_\n\n# Get the indices of the features sorted by importance\nindices = np.argsort(importances)[::-1]\n\n# Get the feature names\nfeature_names = X_TRAIN_FEATURES\n#print(X_train_r.shape[1], \"\\n\")\n# Display the feature importances\n#print(\"Feature ranking:\")\n\n#for f in range(X_train_r.shape[1]):\n#    print(f\"{f + 1}. {feature_names[indices[f]]}: {importances[indices[f]]:.4f}\")\n\n#Plot the feature importances\n#plt.figure(figsize=(10, 6))\n#plt.title(\"Feature importances\")\n#plt.bar(range(X_train_r.shape[1]), importances[indices], align=\"center\")\n#plt.xticks(range(X_train_r.shape[1]), np.array(feature_names)[indices], rotation=45)\n#plt.xlim([-1, X_train_r.shape[1]])\n#plt.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.6)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:31.126423Z","iopub.execute_input":"2023-11-15T03:30:31.126839Z","iopub.status.idle":"2023-11-15T03:30:36.117489Z","shell.execute_reply.started":"2023-11-15T03:30:31.126769Z","shell.execute_reply":"2023-11-15T03:30:36.116766Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"76800\n76800\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"#Benchmark method: Try linear regression based on only:\n#1) whether a given pixel is currently on fire and \n#2) number of neighbors that are currently on fire\n\n#Vectorize previous fire masks\nflat_prev_masks = []\n\n#Remembering that Python is zero-indexed is going to be VERY IMPORTANT in the below!\nfor obs in range(certain_prev_masks.shape[2]):\n    for row in range(certain_prev_masks.shape[0]):\n        for col in range(certain_prev_masks.shape[1]):\n            flat_prev_masks.append(certain_prev_masks[row, col, obs])\nflat_prev_masks = np.array(flat_prev_masks)\n\n#Vectorize euc distance\nflat_euclid_distance = []\nfor obs in range(euclid_distance.shape[2]):\n    for row in range(euclid_distance.shape[0]):\n        for col in range(euclid_distance.shape[1]):\n            flat_euclid_distance.append(euclid_distance[row, col, obs])\nflat_euclid_distance = np.array(flat_euclid_distance)\n\nflat_elevation = []\nfor obs in range(cleaned_elevation.shape[2]):\n    for row in range(cleaned_elevation.shape[0]):\n        for col in range(cleaned_elevation.shape[1]):\n            flat_elevation.append(cleaned_elevation[row, col, obs])\nflat_elevation = np.array(flat_elevation)\n\nflat_wind_dir = []\nfor obs in range(cleaned_wind_dir.shape[2]):\n    for row in range(cleaned_wind_dir.shape[0]):\n        for col in range(cleaned_wind_dir.shape[1]):\n            flat_wind_dir.append(cleaned_wind_dir[row, col, obs])\nflat_wind_dir = np.array(flat_wind_dir)\n\nflat_wind_velo = []\nfor obs in range(cleaned_wind_velo.shape[2]):\n    for row in range(cleaned_wind_velo.shape[0]):\n        for col in range(cleaned_wind_velo.shape[1]):\n            flat_wind_velo.append(cleaned_wind_velo[row, col, obs])\nflat_wind_velo = np.array(flat_wind_velo)\n\nflat_temp_min = []\nfor obs in range(cleaned_temp_min.shape[2]):\n    for row in range(cleaned_temp_min.shape[0]):\n        for col in range(cleaned_temp_min.shape[1]):\n            flat_temp_min.append(cleaned_temp_min[row, col, obs])\nflat_temp_min = np.array(flat_temp_min)\n\nflat_temp_max = []\nfor obs in range(cleaned_temp_max.shape[2]):\n    for row in range(cleaned_temp_max.shape[0]):\n        for col in range(cleaned_temp_max.shape[1]):\n            flat_temp_max.append(cleaned_temp_max[row, col, obs])\nflat_temp_max = np.array(flat_temp_max)\n\nflat_humidity = []\nfor obs in range(cleaned_humidity.shape[2]):\n    for row in range(cleaned_humidity.shape[0]):\n        for col in range(cleaned_humidity.shape[1]):\n            flat_humidity.append(cleaned_humidity[row, col, obs])\nflat_humidity = np.array(flat_humidity)\n\nflat_precipitation = []\nfor obs in range(cleaned_precipitation.shape[2]):\n    for row in range(cleaned_precipitation.shape[0]):\n        for col in range(cleaned_precipitation.shape[1]):\n            flat_precipitation.append(cleaned_precipitation[row, col, obs])\nflat_precipitation = np.array(flat_precipitation)\n\nflat_drought = []\nfor obs in range(cleaned_drought.shape[2]):\n    for row in range(cleaned_drought.shape[0]):\n        for col in range(cleaned_drought.shape[1]):\n            flat_drought.append(cleaned_drought[row, col, obs])\nflat_drought = np.array(flat_drought)\n\nflat_vegetation = []\nfor obs in range(cleaned_vegetation.shape[2]):\n    for row in range(cleaned_vegetation.shape[0]):\n        for col in range(cleaned_vegetation.shape[1]):\n            flat_vegetation.append(cleaned_vegetation[row, col, obs])\nflat_vegetation = np.array(flat_vegetation)\n\nflat_population = []\nfor obs in range(cleaned_population.shape[2]):\n    for row in range(cleaned_population.shape[0]):\n        for col in range(cleaned_population.shape[1]):\n            flat_population.append(cleaned_population[row, col, obs])\nflat_population = np.array(flat_population)\n\nflat_ERC = []\nfor obs in range(cleaned_ERC.shape[2]):\n    for row in range(cleaned_ERC.shape[0]):\n        for col in range(cleaned_ERC.shape[1]):\n            flat_ERC.append(cleaned_ERC[row, col, obs])\nflat_ERC = np.array(flat_ERC)\n\n#print(flat_prev_masks.shape)\n#print(flat_avg_nbrs.shape)\nX_TRAIN_FEATURES = ['prev_fire', \n                    'euclid_distance', \n                    'elevation', 'wind_dir', 'wind_velo', 'temp_min', 'temp_max', 'humidity', 'precipitation', 'drought', 'vegetation', 'population', 'ERC']\nX_train = np.vstack((\n    np.transpose(flat_prev_masks), \n    np.transpose(flat_euclid_distance),\n    np.transpose(flat_elevation),\n    np.transpose(flat_wind_dir),\n    np.transpose(flat_wind_velo),\n    np.transpose(flat_temp_min),\n    np.transpose(flat_temp_max),\n    np.transpose(flat_humidity),\n    np.transpose(flat_precipitation),\n    np.transpose(flat_drought),\n    np.transpose(flat_vegetation),\n    np.transpose(flat_population),\n    np.transpose(flat_ERC)\n))\n\nX_train = np.transpose(X_train) #so that observations correspond to rows now\n\n#Vectorize labels\nflat_labels = []\nfor obs in range(certain_labels.shape[2]):\n    for row in range(certain_labels.shape[0]):\n        for col in range(certain_labels.shape[1]):\n            flat_labels.append(certain_labels[row, col, obs])\nflat_labels = np.array(flat_labels)\n\nY_train = flat_labels\n#print(Y_train.shape)\n\nvariables = [\"currently on fire?\", \"# of neighbors currently on fire\"]\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n\nX_train_r, X_test_r, Y_train_r, Y_test_r = train_test_split(X_train, Y_train, test_size=0.20, random_state=42)\n\nmodel = RandomForestClassifier(criterion = \"gini\", n_estimators = 15)\nmodel.fit(X_train_r, Y_train_r)\nprint(model.score(X_test_r, Y_test_r))\n\n\nX = np.column_stack((X_train_r, model.predict_proba(X_train_r)[:, 1]))  # Combining original features with RF predictions\nY = Y_train_r  # Adjust according to your data\n\nparam = {\n    'max_depth': 3,\n    'eta': 0.3,\n    'objective': 'reg:squarederror'\n}\nnum_round = 50\nkf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\naccuracies = []\n\nfor train_index, val_index in kf.split(X):\n    X_train_r, X_val = X[train_index], X[val_index]\n    Y_train_r, Y_val = Y[train_index], Y[val_index]\n    \n    dtrain = xgb.DMatrix(X_train_r, label=Y_train_r)\n    dval = xgb.DMatrix(X_val, label=Y_val)\n    \n    bst = xgb.train(param, dtrain, num_round)\n    \n    predictions = bst.predict(dval)\n    predicted_labels = [1 if p > 0.5 else 0 for p in predictions]\n    \n    acc = accuracy_score(Y_val, predicted_labels)\n    accuracies.append(acc)\n\naverage_accuracy = np.mean(accuracies)\nprint(f\"Average Accuracy across folds: {average_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:40:26.558802Z","iopub.execute_input":"2023-11-15T00:40:26.559179Z","iopub.status.idle":"2023-11-15T00:40:41.435596Z","shell.execute_reply.started":"2023-11-15T00:40:26.559140Z","shell.execute_reply":"2023-11-15T00:40:41.433881Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"0.9796223958333333\nAverage Accuracy across folds: 0.9968\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Gridsearch","metadata":{}},{"cell_type":"code","source":"#Benchmark method: Try linear regression based on only:\n#1) whether a given pixel is currently on fire and \n#2) number of neighbors that are currently on fire\n\n#Vectorize previous fire masks\nflat_prev_masks = []\n\n#Remembering that Python is zero-indexed is going to be VERY IMPORTANT in the below!\nfor obs in range(certain_prev_masks.shape[2]):\n    for row in range(certain_prev_masks.shape[0]):\n        for col in range(certain_prev_masks.shape[1]):\n            flat_prev_masks.append(certain_prev_masks[row, col, obs])\nflat_prev_masks = np.array(flat_prev_masks)\n\n#Vectorize euc distance\nflat_euclid_distance = []\nfor obs in range(euclid_distance.shape[2]):\n    for row in range(euclid_distance.shape[0]):\n        for col in range(euclid_distance.shape[1]):\n            flat_euclid_distance.append(euclid_distance[row, col, obs])\nflat_euclid_distance = np.array(flat_euclid_distance)\n\nflat_elevation = []\nfor obs in range(cleaned_elevation.shape[2]):\n    for row in range(cleaned_elevation.shape[0]):\n        for col in range(cleaned_elevation.shape[1]):\n            flat_elevation.append(cleaned_elevation[row, col, obs])\nflat_elevation = np.array(flat_elevation)\n\nflat_wind_dir = []\nfor obs in range(cleaned_wind_dir.shape[2]):\n    for row in range(cleaned_wind_dir.shape[0]):\n        for col in range(cleaned_wind_dir.shape[1]):\n            flat_wind_dir.append(cleaned_wind_dir[row, col, obs])\nflat_wind_dir = np.array(flat_wind_dir)\n\nflat_wind_velo = []\nfor obs in range(cleaned_wind_velo.shape[2]):\n    for row in range(cleaned_wind_velo.shape[0]):\n        for col in range(cleaned_wind_velo.shape[1]):\n            flat_wind_velo.append(cleaned_wind_velo[row, col, obs])\nflat_wind_velo = np.array(flat_wind_velo)\n\nflat_temp_min = []\nfor obs in range(cleaned_temp_min.shape[2]):\n    for row in range(cleaned_temp_min.shape[0]):\n        for col in range(cleaned_temp_min.shape[1]):\n            flat_temp_min.append(cleaned_temp_min[row, col, obs])\nflat_temp_min = np.array(flat_temp_min)\n\nflat_temp_max = []\nfor obs in range(cleaned_temp_max.shape[2]):\n    for row in range(cleaned_temp_max.shape[0]):\n        for col in range(cleaned_temp_max.shape[1]):\n            flat_temp_max.append(cleaned_temp_max[row, col, obs])\nflat_temp_max = np.array(flat_temp_max)\n\nflat_humidity = []\nfor obs in range(cleaned_humidity.shape[2]):\n    for row in range(cleaned_humidity.shape[0]):\n        for col in range(cleaned_humidity.shape[1]):\n            flat_humidity.append(cleaned_humidity[row, col, obs])\nflat_humidity = np.array(flat_humidity)\n\nflat_precipitation = []\nfor obs in range(cleaned_precipitation.shape[2]):\n    for row in range(cleaned_precipitation.shape[0]):\n        for col in range(cleaned_precipitation.shape[1]):\n            flat_precipitation.append(cleaned_precipitation[row, col, obs])\nflat_precipitation = np.array(flat_precipitation)\n\nflat_drought = []\nfor obs in range(cleaned_drought.shape[2]):\n    for row in range(cleaned_drought.shape[0]):\n        for col in range(cleaned_drought.shape[1]):\n            flat_drought.append(cleaned_drought[row, col, obs])\nflat_drought = np.array(flat_drought)\n\nflat_vegetation = []\nfor obs in range(cleaned_vegetation.shape[2]):\n    for row in range(cleaned_vegetation.shape[0]):\n        for col in range(cleaned_vegetation.shape[1]):\n            flat_vegetation.append(cleaned_vegetation[row, col, obs])\nflat_vegetation = np.array(flat_vegetation)\n\nflat_population = []\nfor obs in range(cleaned_population.shape[2]):\n    for row in range(cleaned_population.shape[0]):\n        for col in range(cleaned_population.shape[1]):\n            flat_population.append(cleaned_population[row, col, obs])\nflat_population = np.array(flat_population)\n\nflat_ERC = []\nfor obs in range(cleaned_ERC.shape[2]):\n    for row in range(cleaned_ERC.shape[0]):\n        for col in range(cleaned_ERC.shape[1]):\n            flat_ERC.append(cleaned_ERC[row, col, obs])\nflat_ERC = np.array(flat_ERC)\n\n#print(flat_prev_masks.shape)\n#print(flat_avg_nbrs.shape)\nX_TRAIN_FEATURES = ['prev_fire', \n                    'euclid_distance', \n                    'elevation', 'wind_dir', 'wind_velo', 'temp_min', 'temp_max', 'humidity', 'precipitation', 'drought', 'vegetation', 'population', 'ERC']\nX_train = np.vstack((\n    np.transpose(flat_prev_masks), \n    np.transpose(flat_euclid_distance),\n    np.transpose(flat_elevation),\n    np.transpose(flat_wind_dir),\n    np.transpose(flat_wind_velo),\n    np.transpose(flat_temp_min),\n    np.transpose(flat_temp_max),\n    np.transpose(flat_humidity),\n    np.transpose(flat_precipitation),\n    np.transpose(flat_drought),\n    np.transpose(flat_vegetation),\n    np.transpose(flat_population),\n    np.transpose(flat_ERC)\n))\n\nX_train = np.transpose(X_train) #so that observations correspond to rows now\n\n#Vectorize labels\nflat_labels = []\nfor obs in range(certain_labels.shape[2]):\n    for row in range(certain_labels.shape[0]):\n        for col in range(certain_labels.shape[1]):\n            flat_labels.append(certain_labels[row, col, obs])\nflat_labels = np.array(flat_labels)\n\nY_train = flat_labels\n#print(Y_train.shape)\n\nvariables = [\"currently on fire?\", \"# of neighbors currently on fire\"]\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n\nX_train_r, X_test_r, Y_train_r, Y_test_r = train_test_split(X_train, Y_train, test_size=0.20, random_state=42)\n\nmodel = RandomForestClassifier(criterion = \"gini\", n_estimators = 15)\nmodel.fit(X_train_r, Y_train_r)\nprint(model.score(X_test_r, Y_test_r))\n\nX = np.column_stack((X_train_r, model.predict_proba(X_train_r)[:, 1]))  # Combining original features with RF predictions\nY = Y_train_r  # Adjust according to your data\n\n# GridSearchCV implementation\nparam_grid = {\n    'max_depth': [3, 4, 5],\n    'eta': [0.1, 0.2, 0.3],\n    'objective': ['reg:squarederror'],\n    'n_estimators': [10, 50, 100]\n}\n\n# Convert the data to DMatrix format\ndtrain = xgb.DMatrix(X, label=Y)\n\n# Create a train/test split for the grid search validation\nX_train_gs, X_val_gs, Y_train_gs, Y_val_gs = train_test_split(X, Y, test_size=0.20, random_state=42)\n\n# Initialize the XGBoost classifier\nxgb_model = xgb.XGBClassifier()\n\n# Set up the grid search\ngrid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy', verbose=1)\n\n# Fit the model\ngrid_search.fit(X_train_gs, Y_train_gs)\n\n# Print the best parameters and score\nprint(\"Best parameters found: \", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n\n# Predict on the validation set\npredicted_labels_gs = grid_search.predict(X_val_gs)\nacc_gs = accuracy_score(Y_val_gs, predicted_labels_gs)\nprint(f\"Accuracy on validation set: {acc_gs:.4f}\")\n\n# Continue with your KFold cross-validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\naccuracies = []\n\nfor train_index, val_index in kf.split(X):\n    X_train_r, X_val = X[train_index], X[val_index]\n    Y_train_r, Y_val = Y[train_index], Y[val_index]\n    \n    dtrain = xgb.DMatrix(X_train_r, label=Y_train_r)\n    dval = xgb.DMatrix(X_val, label=Y_val)\n    \n    bst = xgb.train(grid_search.best_params_, dtrain, grid_search.best_params_['n_estimators'])\n    \n    predictions = bst.predict(dval)\n    predicted_labels = [1 if p > 0.5 else 0 for p in predictions]\n    \n    acc = accuracy_score(Y_val, predicted_labels)\n    accuracies.append(acc)\n\naverage_accuracy = np.mean(accuracies)\nprint(f\"Average Accuracy across folds using best parameters: {average_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:48:34.399019Z","iopub.execute_input":"2023-11-15T00:48:34.399374Z","iopub.status.idle":"2023-11-15T00:58:22.862358Z","shell.execute_reply.started":"2023-11-15T00:48:34.399339Z","shell.execute_reply":"2023-11-15T00:58:22.861345Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"0.9805338541666667\nFitting 5 folds for each of 27 candidates, totalling 135 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[00:48:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:48:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:48:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:48:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:48:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:48:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:48:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:48:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:48:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:48:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:49:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:50:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:52:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:53:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:54:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:55:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:56:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:57:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:57:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:57:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:57:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:57:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:57:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed:  9.0min finished\n","output_type":"stream"},{"name":"stdout","text":"[00:57:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nBest parameters found:  {'eta': 0.2, 'max_depth': 5, 'n_estimators': 100, 'objective': 'reg:squarederror'}\nBest cross-validation score: 1.00\nAccuracy on validation set: 0.9986\n[00:57:53] WARNING: ../src/learner.cc:576: \nParameters: { \"n_estimators\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[00:57:59] WARNING: ../src/learner.cc:576: \nParameters: { \"n_estimators\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[00:58:04] WARNING: ../src/learner.cc:576: \nParameters: { \"n_estimators\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[00:58:10] WARNING: ../src/learner.cc:576: \nParameters: { \"n_estimators\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[00:58:17] WARNING: ../src/learner.cc:576: \nParameters: { \"n_estimators\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAverage Accuracy across folds using best parameters: 0.9972\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Autoencoder","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n\n        self.Encoder = nn.Sequential(\n            nn.Conv2d(3,64,kernel_size = (8,8),padding = 2,padding_mode = 'replicate',bias = True),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(kernel_size = (2,2)),\n            ###Now 128*128*64\n            nn.Conv2d(64,64,kernel_size = (5,5),padding = 1,padding_mode = 'replicate',bias = True),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(kernel_size = (2,2)),\n            ###Now 64*64*32\n            nn.Conv2d(64,32,kernel_size = (3,3),padding = 2,padding_mode = 'replicate',bias = True),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(kernel_size = (2,2)),\n            ###Now 32*32*16\n            #nn.Conv2d(16,16,kernel_size = (10,10),padding_mode = 'same',bias = True),\n            #nn.LeakyReLU(0.1),\n            #nn.MaxPool2d(kernel_size = (2,2)))\n        )\n            ###Now 16*16*16\n\n        self.Decoder = nn.Sequential(\n            #nn.ConvTranspose2d(16,16,kernel_size = (3,3)),\n            #nn.LeakyReLU(0.1),\n            nn.ConvTranspose2d(32,64,kernel_size = (3,3),stride = 2, padding = 1),\n            nn.LeakyReLU(0.1),\n            nn.ConvTranspose2d(64,64,kernel_size = (6,6),stride = 2,padding = 1),\n            nn.LeakyReLU(0.1),\n            nn.ConvTranspose2d(64,3,kernel_size = (8,8), stride = 2, padding = 3),\n            nn.Tanh())\n\n    def forward(self,x,corruption):\n        x = self.Encoder(x)\n            #print('Encoder output: ',x.shape)\n        if x.shape == corruption.shape:\n            x = x * corruption\n        else:\n            corruption = corruption[0:len(x)]\n            x = x * corruption\n        x = self.Decoder(x)\n        #print('Decoder output: ',x.shape)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T01:38:51.176541Z","iopub.execute_input":"2023-11-15T01:38:51.176965Z","iopub.status.idle":"2023-11-15T01:38:51.193807Z","shell.execute_reply.started":"2023-11-15T01:38:51.176919Z","shell.execute_reply":"2023-11-15T01:38:51.192883Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#Vectorize previous fire masks\nflat_prev_masks = []\n\n#Remembering that Python is zero-indexed is going to be VERY IMPORTANT in the below!\nfor obs in range(certain_prev_masks.shape[2]):\n    for row in range(certain_prev_masks.shape[0]):\n        for col in range(certain_prev_masks.shape[1]):\n            flat_prev_masks.append(certain_prev_masks[row, col, obs])\nflat_prev_masks = np.array(flat_prev_masks)\n\n#Vectorize euc distance\nflat_euclid_distance = []\nfor obs in range(euclid_distance.shape[2]):\n    for row in range(euclid_distance.shape[0]):\n        for col in range(euclid_distance.shape[1]):\n            flat_euclid_distance.append(euclid_distance[row, col, obs])\nflat_euclid_distance = np.array(flat_euclid_distance)\n\nflat_elevation = []\nfor obs in range(cleaned_elevation.shape[2]):\n    for row in range(cleaned_elevation.shape[0]):\n        for col in range(cleaned_elevation.shape[1]):\n            flat_elevation.append(cleaned_elevation[row, col, obs])\nflat_elevation = np.array(flat_elevation)\n\nflat_wind_dir = []\nfor obs in range(cleaned_wind_dir.shape[2]):\n    for row in range(cleaned_wind_dir.shape[0]):\n        for col in range(cleaned_wind_dir.shape[1]):\n            flat_wind_dir.append(cleaned_wind_dir[row, col, obs])\nflat_wind_dir = np.array(flat_wind_dir)\n\nflat_wind_velo = []\nfor obs in range(cleaned_wind_velo.shape[2]):\n    for row in range(cleaned_wind_velo.shape[0]):\n        for col in range(cleaned_wind_velo.shape[1]):\n            flat_wind_velo.append(cleaned_wind_velo[row, col, obs])\nflat_wind_velo = np.array(flat_wind_velo)\n\nflat_temp_min = []\nfor obs in range(cleaned_temp_min.shape[2]):\n    for row in range(cleaned_temp_min.shape[0]):\n        for col in range(cleaned_temp_min.shape[1]):\n            flat_temp_min.append(cleaned_temp_min[row, col, obs])\nflat_temp_min = np.array(flat_temp_min)\n\nflat_temp_max = []\nfor obs in range(cleaned_temp_max.shape[2]):\n    for row in range(cleaned_temp_max.shape[0]):\n        for col in range(cleaned_temp_max.shape[1]):\n            flat_temp_max.append(cleaned_temp_max[row, col, obs])\nflat_temp_max = np.array(flat_temp_max)\n\nflat_humidity = []\nfor obs in range(cleaned_humidity.shape[2]):\n    for row in range(cleaned_humidity.shape[0]):\n        for col in range(cleaned_humidity.shape[1]):\n            flat_humidity.append(cleaned_humidity[row, col, obs])\nflat_humidity = np.array(flat_humidity)\n\nflat_precipitation = []\nfor obs in range(cleaned_precipitation.shape[2]):\n    for row in range(cleaned_precipitation.shape[0]):\n        for col in range(cleaned_precipitation.shape[1]):\n            flat_precipitation.append(cleaned_precipitation[row, col, obs])\nflat_precipitation = np.array(flat_precipitation)\n\nflat_drought = []\nfor obs in range(cleaned_drought.shape[2]):\n    for row in range(cleaned_drought.shape[0]):\n        for col in range(cleaned_drought.shape[1]):\n            flat_drought.append(cleaned_drought[row, col, obs])\nflat_drought = np.array(flat_drought)\n\nflat_vegetation = []\nfor obs in range(cleaned_vegetation.shape[2]):\n    for row in range(cleaned_vegetation.shape[0]):\n        for col in range(cleaned_vegetation.shape[1]):\n            flat_vegetation.append(cleaned_vegetation[row, col, obs])\nflat_vegetation = np.array(flat_vegetation)\n\nflat_population = []\nfor obs in range(cleaned_population.shape[2]):\n    for row in range(cleaned_population.shape[0]):\n        for col in range(cleaned_population.shape[1]):\n            flat_population.append(cleaned_population[row, col, obs])\nflat_population = np.array(flat_population)\n\nflat_ERC = []\nfor obs in range(cleaned_ERC.shape[2]):\n    for row in range(cleaned_ERC.shape[0]):\n        for col in range(cleaned_ERC.shape[1]):\n            flat_ERC.append(cleaned_ERC[row, col, obs])\nflat_ERC = np.array(flat_ERC)\n\n#print(flat_prev_masks.shape)\n#print(flat_avg_nbrs.shape)\nX_TRAIN_FEATURES = ['prev_fire', \n                    'euclid_distance', \n                    'elevation', 'wind_dir', 'wind_velo', 'temp_min', 'temp_max', 'humidity', 'precipitation', 'drought', 'vegetation', 'population', 'ERC']\nX_train = np.vstack((\n    np.transpose(flat_prev_masks), \n    np.transpose(flat_euclid_distance),\n    np.transpose(flat_elevation),\n    np.transpose(flat_wind_dir),\n    np.transpose(flat_wind_velo),\n    np.transpose(flat_temp_min),\n    np.transpose(flat_temp_max),\n    np.transpose(flat_humidity),\n    np.transpose(flat_precipitation),\n    np.transpose(flat_drought),\n    np.transpose(flat_vegetation),\n    np.transpose(flat_population),\n    np.transpose(flat_ERC)\n))\n\nX_train = np.transpose(X_train) #so that observations correspond to rows now\n\n#Vectorize labels\nflat_labels = []\nfor obs in range(certain_labels.shape[2]):\n    for row in range(certain_labels.shape[0]):\n        for col in range(certain_labels.shape[1]):\n            flat_labels.append(certain_labels[row, col, obs])\nflat_labels = np.array(flat_labels)\n\nY_train = flat_labels\n#print(Y_train.shape)\n\nvariables = [\"currently on fire?\", \"# of neighbors currently on fire\"]\n\nfrom sklearn.model_selection import train_test_split\nX_train_r, X_test_r, Y_train_r, Y_test_r = train_test_split(X_train, Y_train, test_size=0.20, random_state=42)\n\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Assuming X_train and Y_train are numpy arrays of your dataset\n# Convert the datasets to PyTorch tensors\nX_train_tensor = torch.tensor(X_train_r, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test_r, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_r, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_r, dtype=torch.float32)\n\n# Assuming the corruption mask is meant to be some kind of dropout mask\ncorruption_mask = torch.ones_like(X_train_tensor)\n\n# Create datasets and dataloaders\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Initialize the autoencoder model\nautoencoder = Autoencoder()\n\n# Loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n\n# Move the model and corruption mask to the appropriate device (CPU or GPU)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nautoencoder = autoencoder.to(device)\ncorruption_mask = corruption_mask.to(device)\n\nnum_epochs = 10\n\n# Training loop\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    for data in train_dataloader:\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = autoencoder(inputs, corruption_mask)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        # Print statistics\n        running_loss += loss.item()\n\n    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_dataloader)}')\n\n# Optionally, test the model\nwith torch.no_grad():\n    test_loss = 0.0\n    for data in test_dataloader:\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = autoencoder(inputs, corruption_mask)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n\n    print(f'Test Loss: {test_loss/len(test_dataloader)}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T01:39:01.456593Z","iopub.execute_input":"2023-11-15T01:39:01.456958Z","iopub.status.idle":"2023-11-15T01:39:02.696801Z","shell.execute_reply.started":"2023-11-15T01:39:01.456906Z","shell.execute_reply":"2023-11-15T01:39:02.695328Z"},"trusted":true},"execution_count":39,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_20/2707536379.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorruption_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_20/3514626997.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, corruption)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorruption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;31m#print('Encoder output: ',x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcorruption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'zeros'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n\u001b[0m\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   4187\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4189\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only 3D, 4D, 5D padding with non-constant padding are supported for now\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: Only 3D, 4D, 5D padding with non-constant padding are supported for now"],"ename":"NotImplementedError","evalue":"Only 3D, 4D, 5D padding with non-constant padding are supported for now","output_type":"error"}]},{"cell_type":"markdown","source":"## Autoencoder v2","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\n\n# Creating a PyTorch class\n# 28*28 ==> 9 ==> 28*28\nclass AE(torch.nn.Module):\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\t\n\t\t# Building an linear encoder with Linear\n\t\t# layer followed by Relu activation function\n\t\t# 784 ==> 9\n\t\tself.encoder = torch.nn.Sequential(\n\t\t\ttorch.nn.Linear(28 * 28, 128),\n\t\t\ttorch.nn.ReLU(),\n\t\t\ttorch.nn.Linear(128, 64),\n\t\t\ttorch.nn.ReLU(),\n\t\t\ttorch.nn.Linear(64, 36),\n\t\t\ttorch.nn.ReLU(),\n\t\t\ttorch.nn.Linear(36, 18),\n\t\t\ttorch.nn.ReLU(),\n\t\t\ttorch.nn.Linear(18, 9)\n\t\t)\n\t\t\n\t\t# Building an linear decoder with Linear\n\t\t# layer followed by Relu activation function\n\t\t# The Sigmoid activation function\n\t\t# outputs the value between 0 and 1\n\t\t# 9 ==> 784\n\t\tself.decoder = torch.nn.Sequential(\n\t\t\ttorch.nn.Linear(9, 18),\n\t\t\ttorch.nn.ReLU(),\n\t\t\ttorch.nn.Linear(18, 36),\n\t\t\ttorch.nn.ReLU(),\n\t\t\ttorch.nn.Linear(36, 64),\n\t\t\ttorch.nn.ReLU(),\n\t\t\ttorch.nn.Linear(64, 128),\n\t\t\ttorch.nn.ReLU(),\n\t\t\ttorch.nn.Linear(128, 28 * 28),\n\t\t\ttorch.nn.Sigmoid()\n\t\t)\n\n\tdef forward(self, x):\n\t\tencoded = self.encoder(x)\n\t\tdecoded = self.decoder(encoded)\n\t\treturn decoded\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T02:26:51.136535Z","iopub.execute_input":"2023-11-15T02:26:51.136980Z","iopub.status.idle":"2023-11-15T02:26:51.389848Z","shell.execute_reply.started":"2023-11-15T02:26:51.136935Z","shell.execute_reply":"2023-11-15T02:26:51.388740Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Load","metadata":{}},{"cell_type":"code","source":"#Vectorize previous fire masks\nflat_prev_masks = []\n\n#Remembering that Python is zero-indexed is going to be VERY IMPORTANT in the below!\nfor obs in range(certain_prev_masks.shape[2]):\n    for row in range(certain_prev_masks.shape[0]):\n        for col in range(certain_prev_masks.shape[1]):\n            flat_prev_masks.append(certain_prev_masks[row, col, obs])\nflat_prev_masks = np.array(flat_prev_masks)\n\n#Vectorize euc distance\nflat_euclid_distance = []\nfor obs in range(euclid_distance.shape[2]):\n    for row in range(euclid_distance.shape[0]):\n        for col in range(euclid_distance.shape[1]):\n            flat_euclid_distance.append(euclid_distance[row, col, obs])\nflat_euclid_distance = np.array(flat_euclid_distance)\n\nflat_elevation = []\nfor obs in range(cleaned_elevation.shape[2]):\n    for row in range(cleaned_elevation.shape[0]):\n        for col in range(cleaned_elevation.shape[1]):\n            flat_elevation.append(cleaned_elevation[row, col, obs])\nflat_elevation = np.array(flat_elevation)\n\nflat_wind_dir = []\nfor obs in range(cleaned_wind_dir.shape[2]):\n    for row in range(cleaned_wind_dir.shape[0]):\n        for col in range(cleaned_wind_dir.shape[1]):\n            flat_wind_dir.append(cleaned_wind_dir[row, col, obs])\nflat_wind_dir = np.array(flat_wind_dir)\n\nflat_wind_velo = []\nfor obs in range(cleaned_wind_velo.shape[2]):\n    for row in range(cleaned_wind_velo.shape[0]):\n        for col in range(cleaned_wind_velo.shape[1]):\n            flat_wind_velo.append(cleaned_wind_velo[row, col, obs])\nflat_wind_velo = np.array(flat_wind_velo)\n\nflat_temp_min = []\nfor obs in range(cleaned_temp_min.shape[2]):\n    for row in range(cleaned_temp_min.shape[0]):\n        for col in range(cleaned_temp_min.shape[1]):\n            flat_temp_min.append(cleaned_temp_min[row, col, obs])\nflat_temp_min = np.array(flat_temp_min)\n\nflat_temp_max = []\nfor obs in range(cleaned_temp_max.shape[2]):\n    for row in range(cleaned_temp_max.shape[0]):\n        for col in range(cleaned_temp_max.shape[1]):\n            flat_temp_max.append(cleaned_temp_max[row, col, obs])\nflat_temp_max = np.array(flat_temp_max)\n\nflat_humidity = []\nfor obs in range(cleaned_humidity.shape[2]):\n    for row in range(cleaned_humidity.shape[0]):\n        for col in range(cleaned_humidity.shape[1]):\n            flat_humidity.append(cleaned_humidity[row, col, obs])\nflat_humidity = np.array(flat_humidity)\n\nflat_precipitation = []\nfor obs in range(cleaned_precipitation.shape[2]):\n    for row in range(cleaned_precipitation.shape[0]):\n        for col in range(cleaned_precipitation.shape[1]):\n            flat_precipitation.append(cleaned_precipitation[row, col, obs])\nflat_precipitation = np.array(flat_precipitation)\n\nflat_drought = []\nfor obs in range(cleaned_drought.shape[2]):\n    for row in range(cleaned_drought.shape[0]):\n        for col in range(cleaned_drought.shape[1]):\n            flat_drought.append(cleaned_drought[row, col, obs])\nflat_drought = np.array(flat_drought)\n\nflat_vegetation = []\nfor obs in range(cleaned_vegetation.shape[2]):\n    for row in range(cleaned_vegetation.shape[0]):\n        for col in range(cleaned_vegetation.shape[1]):\n            flat_vegetation.append(cleaned_vegetation[row, col, obs])\nflat_vegetation = np.array(flat_vegetation)\n\nflat_population = []\nfor obs in range(cleaned_population.shape[2]):\n    for row in range(cleaned_population.shape[0]):\n        for col in range(cleaned_population.shape[1]):\n            flat_population.append(cleaned_population[row, col, obs])\nflat_population = np.array(flat_population)\n\nflat_ERC = []\nfor obs in range(cleaned_ERC.shape[2]):\n    for row in range(cleaned_ERC.shape[0]):\n        for col in range(cleaned_ERC.shape[1]):\n            flat_ERC.append(cleaned_ERC[row, col, obs])\nflat_ERC = np.array(flat_ERC)\n\n#print(flat_prev_masks.shape)\n#print(flat_avg_nbrs.shape)\nX_TRAIN_FEATURES = ['prev_fire', \n                    'euclid_distance', \n                    'elevation', 'wind_dir', 'wind_velo', 'temp_min', 'temp_max', 'humidity', 'precipitation', 'drought', 'vegetation', 'population', 'ERC']\nX_train = np.vstack((\n    np.transpose(flat_prev_masks), \n    np.transpose(flat_euclid_distance),\n    np.transpose(flat_elevation),\n    np.transpose(flat_wind_dir),\n    np.transpose(flat_wind_velo),\n    np.transpose(flat_temp_min),\n    np.transpose(flat_temp_max),\n    np.transpose(flat_humidity),\n    np.transpose(flat_precipitation),\n    np.transpose(flat_drought),\n    np.transpose(flat_vegetation),\n    np.transpose(flat_population),\n    np.transpose(flat_ERC)\n))\n\nX_train = np.transpose(X_train) #so that observations correspond to rows now\n\n#Vectorize labels\nflat_labels = []\nfor obs in range(certain_labels.shape[2]):\n    for row in range(certain_labels.shape[0]):\n        for col in range(certain_labels.shape[1]):\n            flat_labels.append(certain_labels[row, col, obs])\nflat_labels = np.array(flat_labels)\n\nY_train = flat_labels\n#print(Y_train.shape)\n\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n\n# Ensure the dimensions match\nprint(X_train_tensor.shape, Y_train_tensor.shape)\n\n# Create the TensorDataset\ndataset = TensorDataset(X_train_tensor, Y_train_tensor)\n\n# Create the DataLoader\nloader = DataLoader(dataset, batch_size=14, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:43:24.959814Z","iopub.execute_input":"2023-11-15T03:43:24.960215Z","iopub.status.idle":"2023-11-15T03:43:25.929190Z","shell.execute_reply.started":"2023-11-15T03:43:24.960168Z","shell.execute_reply":"2023-11-15T03:43:25.928221Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"torch.Size([76800, 13]) torch.Size([76800])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Initialize","metadata":{}},{"cell_type":"code","source":"# Model Initialization\nmodel_nn = AE()\n\n# Validation using MSE Loss function\nloss_function = torch.nn.MSELoss()\n\n# Using an Adam Optimizer with lr = 0.1\noptimizer = torch.optim.Adam(model_nn.parameters(),\n\t\t\t\t\t\t\tlr = 1e-1,\n\t\t\t\t\t\t\tweight_decay = 1e-8)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:44:04.072086Z","iopub.execute_input":"2023-11-15T03:44:04.072425Z","iopub.status.idle":"2023-11-15T03:44:04.083573Z","shell.execute_reply.started":"2023-11-15T03:44:04.072389Z","shell.execute_reply":"2023-11-15T03:44:04.082541Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"epochs = 20\noutputs = []\nlosses = []\nfor epoch in range(epochs):\n    for (image, _) in loader:\n    \n        # Reshaping the image to (-1, 784)\n        image = image.reshape(-1, 28*28)\n\n        # Output of Autoencoder\n        reconstructed = model_nn(image)\n\n        # Calculating the loss function\n        loss = loss_function(reconstructed, image)\n\n        # The gradients are set to zero,\n        # the gradient is computed and stored.\n        # .step() performs parameter update\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Storing the losses in a list for plotting\n        losses.append(loss)\n    outputs.append((epochs, image, reconstructed))\n\n# Defining the Plot Style\nplt.style.use('fivethirtyeight')\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\n\n# Plotting the last 100 values\nplt.plot(losses[-100:])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:45:27.769038Z","iopub.execute_input":"2023-11-15T03:45:27.769364Z","iopub.status.idle":"2023-11-15T03:45:27.838997Z","shell.execute_reply.started":"2023-11-15T03:45:27.769328Z","shell.execute_reply":"2023-11-15T03:45:27.837297Z"},"trusted":true},"execution_count":55,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_20/2888299507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Reshaping the image to (-1, 784)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Output of Autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 784]' is invalid for input of size 182"],"ename":"RuntimeError","evalue":"shape '[-1, 784]' is invalid for input of size 182","output_type":"error"}]},{"cell_type":"markdown","source":"## Reconstruct","metadata":{}},{"cell_type":"code","source":"for i, item in enumerate(image):\n\n    # Reshape the array for plotting\n    item = item.reshape(-1, 28, 28)\n    plt.imshow(item[0])\n\nfor i, item in enumerate(reconstructed):\n    item = item.reshape(-1, 28, 28)\n    plt.imshow(item[0])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting function","metadata":{"id":"bzCgCoxtgP-f"}},{"cell_type":"markdown","source":"Let's plot the data!\n\nFirst we define the names for each of our variables.","metadata":{}},{"cell_type":"code","source":"TITLES = [\n  'Elevation',\n  'Wind\\ndirection',\n  'Wind\\nvelocity',\n  'Min\\ntemp',\n  'Max\\ntemp',\n  'Humidity',\n  'Precip',\n  'Drought',\n  'Vegetation',\n  'Population\\ndensity',\n  'Energy\\nrelease\\ncomponent',\n  'Previous\\nfire\\nmask',\n  'Fire\\nmask'\n]","metadata":{"id":"bnG0_l_ChjUt","execution":{"iopub.status.busy":"2023-11-15T00:12:51.325761Z","iopub.status.idle":"2023-11-15T00:12:51.326133Z","shell.execute_reply.started":"2023-11-15T00:12:51.325944Z","shell.execute_reply":"2023-11-15T00:12:51.325963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define some helper variables for the plot. ","metadata":{}},{"cell_type":"code","source":"# Number of rows of data samples to plot\nn_rows = 5 \n# Number of data variables\nn_features = inputs.shape[3]\n# Variables for controllong the color map for the fire masks\nCMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\nBOUNDS = [-1, -0.1, 0.001, 1]\nNORM = colors.BoundaryNorm(BOUNDS, CMAP.N)","metadata":{"id":"G0E6lWR9beD0","execution":{"iopub.status.busy":"2023-11-15T00:12:51.327163Z","iopub.status.idle":"2023-11-15T00:12:51.327500Z","shell.execute_reply.started":"2023-11-15T00:12:51.327316Z","shell.execute_reply":"2023-11-15T00:12:51.327335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,6.5))\n\nfor i in range(n_rows):\n  for j in range(n_features + 1):\n    plt.subplot(n_rows, n_features + 1, i * (n_features + 1) + j + 1)\n    if i == 0:\n      plt.title(TITLES[j], fontsize=13)\n    if j < n_features - 1:\n      plt.imshow(inputs[i, :, :, j], cmap='viridis')\n    if j == n_features - 1:\n      plt.imshow(inputs[i, :, :, -1], cmap=CMAP, norm=NORM)\n    if j == n_features:\n      plt.imshow(labels[i, :, :, 0], cmap=CMAP, norm=NORM) \n    plt.axis('off')\nplt.tight_layout()","metadata":{"id":"sPtKQzQv71J_","outputId":"6694ad6e-0044-4fbc-b184-f615ac14a885","execution":{"iopub.status.busy":"2023-11-15T00:12:51.328740Z","iopub.status.idle":"2023-11-15T00:12:51.330801Z","shell.execute_reply.started":"2023-11-15T00:12:51.330448Z","shell.execute_reply":"2023-11-15T00:12:51.330481Z"},"trusted":true},"execution_count":null,"outputs":[]}]}